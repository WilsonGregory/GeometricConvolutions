{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidwhogg/EmuCosmoSim/blob/main/ipynb/group_averaging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGB_OA6Cvlah"
      },
      "source": [
        "# Finding equivariant convolution operators by group averaging\n",
        "\n",
        "## Authors:\n",
        "- **David W. Hogg** (NYU) (Flatiron)\n",
        "- **Soledad Villar** (JHU)\n",
        "\n",
        "## License\n",
        "Copyright 2022 the authors. All rights reserved *for now*.\n",
        "\n",
        "## To-do\n",
        "- Make the code so it doesn't have a set of `scalar_filter` functions and `vector_filter` functions and so on. The functions should just take `k` as an input.\n",
        "- Make structure so the code is agnostic about scalar/vector/tensor? That is, such that the objects know their own transformation properties? And norms? And visualization methods?\n",
        "\n",
        "## Bugs:\n",
        "- This code transmits `D, M, pixels, keys` as global variables, not by reading them off inputs (or getting them as inputs).\n",
        "- Haven't figured out yet how to visualize the 2-tensor filters; maybe plot eigenvalues and eigenvectors?\n",
        "- The group operators should be found by recursion; this ought to be more efficient.\n",
        "- Fix 3-d plotting so it does a real projection (not just a set of incomprehensible hacks).\n",
        "- We switched from M to 2m+1, make it consistent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q52E4gJ8UfGG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pylab as plt\n",
        "import itertools as it\n",
        "import scipy.signal as sig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yP10B3wza7FO"
      },
      "outputs": [],
      "source": [
        "# Set integers:\n",
        "D = 2 # D-dimensional image (must be 2 or 3 for plotting to work)\n",
        "M = 5 # must be an odd integer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the group ready and test it"
      ],
      "metadata": {
        "id": "kXuKZ19NscF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fvi8Vw0Z6mFh"
      },
      "outputs": [],
      "source": [
        "# Make all possible group generators\n",
        "\n",
        "# Make the flip operator\n",
        "foo = np.ones(D).astype(int)\n",
        "foo[0] = -1\n",
        "gg = np.diag(foo).astype(int)\n",
        "generators = [gg, ]\n",
        "\n",
        "# Make the 90-degree rotation operators\n",
        "for i in range(D):\n",
        "    for j in range(i + 1, D):\n",
        "        gg = np.eye(D).astype(int)\n",
        "        gg[i, i] = 0\n",
        "        gg[j, j] = 0\n",
        "        gg[i, j] = -1\n",
        "        gg[j, i] = 1\n",
        "        generators.append(gg)\n",
        "generators = np.array(generators)\n",
        "\n",
        "# Look at them\n",
        "for gg in generators:\n",
        "    print(gg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXUqQpE8VlAy"
      },
      "outputs": [],
      "source": [
        "# Make all possible group operators.\n",
        "# This code is very wasteful; there is a better way with recursion.\n",
        "\n",
        "def make_all_operators(generators):\n",
        "    operators = np.array([np.eye(D).astype(int), ])\n",
        "    foo = 0\n",
        "    while len(operators) != foo:\n",
        "        foo = len(operators)\n",
        "        operators = make_new_operators(operators, generators)\n",
        "    return(operators)\n",
        "\n",
        "def make_new_operators(operators, generators):\n",
        "    for op in operators:\n",
        "        for gg in generators:\n",
        "            op2 = (gg @ op).astype(int)\n",
        "            operators = np.unique(np.append(operators, op2[None, :, :], axis=0), axis=0)\n",
        "    return operators\n",
        "\n",
        "group_operators = make_all_operators(generators)\n",
        "print(\"I found\", len(group_operators), \"group operators; here are their determinants:\")\n",
        "for gg in group_operators:\n",
        "    print(gg, \"determinant:\", np.linalg.slogdet(gg)[0].astype(int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n960Qo6yY2p5"
      },
      "outputs": [],
      "source": [
        "# Check that the list of group operators is closed\n",
        "for gg in group_operators:\n",
        "    for gg2 in group_operators:\n",
        "        assert ((gg @ gg2).astype(int) in group_operators)\n",
        "    print(gg, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uC_pQ6kLqtR"
      },
      "outputs": [],
      "source": [
        "# Check that gg.T is gg.inv for all gg in group?\n",
        "for gg in group_operators:\n",
        "    print(gg, np.allclose(gg @ gg.T, np.eye(D)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the geometric objects and classes"
      ],
      "metadata": {
        "id": "ZYTHFpILsjnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ktensor:\n",
        "\n",
        "    def __init__(self, data, parity, D=D):\n",
        "        self.D = D\n",
        "        assert self.D > 1, \\\n",
        "        \"ktensor: geometry makes no sense if D<2.\"\n",
        "        self.parity = parity\n",
        "        assert np.abs(self.parity) == 1, \\\n",
        "        \"ktensor: parity must be 1 or -1.\"\n",
        "        if len(np.atleast_1d(data)) == 1:\n",
        "            self.data = data\n",
        "            self.k = 0\n",
        "        else:\n",
        "            self.data = np.array(data)\n",
        "            self.k = len(data.shape)\n",
        "            assert np.all(np.array(data.shape) == D), \\\n",
        "            \"ktensor: shape must be (D, D, D, ...).\"\n",
        "    \n",
        "    def __add__(self, other):\n",
        "        assert self.k == other.k, \\\n",
        "        \"ktensor: can't add objects of different k\"\n",
        "        assert self.parity == other.parity, \\\n",
        "        \"ktensor: can't add objects of different parity\"\n",
        "        return ktensor(self.data + other.data, self.parity)\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        if self.k == 0 or other.k == 0:\n",
        "            return ktensor(self.data * other.data, self.parity * other.parity)\n",
        "        return ktensor(np.outer(self.data, other.data),\n",
        "                       self.parity * other.parity)\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<k-tensor object with k={} and parity={}>\".format(self.k,\n",
        "                                                                 self.parity)\n",
        "\n",
        "    def times_group_element(self, gg):\n",
        "        # BUG: THIS IS UNTESTED.\n",
        "        # BUG: This is incomprehensible.\n",
        "        assert self.k < 14\n",
        "        assert gg.shape == (D, D)\n",
        "        sign, logdet = np.linalg.slogdet(gg)\n",
        "        assert logdet == 0.\n",
        "        if self.k == 0:\n",
        "            newdata = 1. * self.data\n",
        "        else:\n",
        "            firstletters  = \"abcdefghijklm\"\n",
        "            secondletters = \"nopqrstuvwxyz\"\n",
        "            einstr = \"\".join([firstletters[i] for i in range(self.k)]) +\",\" + \\\n",
        "            \",\".join([secondletters[i] + firstletters[i] for i in range(self.k)])\n",
        "            foo = (self.data, ) + self.k * (gg, )\n",
        "            newdata = np.einsum(einstr, *foo)\n",
        "        if self.parity < 0:\n",
        "            newdata *= sign\n",
        "        return ktensor(newdata, self.parity)"
      ],
      "metadata": {
        "id": "bFYRWJgntsPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class geometric_filter:\n",
        "\n",
        "    def make_pixels_and_keys(self):\n",
        "        foo = range(-self.m, self.m + 1)\n",
        "        self.pixels = np.array([pp for pp in it.product(foo, repeat=D)]).astype(int)\n",
        "        self.keys = [tuple(pp) for pp in self.pixels]\n",
        "        return\n",
        "\n",
        "    def __init__(self, data, parity, D=D):\n",
        "        self.D = D\n",
        "        self.M = np.round(len(data) ** (1. / D)).astype(int)\n",
        "        assert len(data) == self.M ** self.D, \\\n",
        "        \"geometric_filter: data doesn't seem to be the right length?\"\n",
        "        self.m = (self.M - 1) // 2\n",
        "        assert self.M == 2 * self.m + 1, \\\n",
        "        \"geometric_filter: M needs to be odd.\"\n",
        "        self.make_pixels_and_keys()\n",
        "        self.parity = parity\n",
        "        self.data = {kk: ktensor(ff, self.parity, self.D)\n",
        "                     for kk, ff in zip(self.keys, data)}\n",
        "        self.k = self.data[self.keys[0]].k\n",
        "        return\n",
        "\n",
        "    def copy(self):\n",
        "        return geometric_filter(self.unpack(), self.parity, self.D)\n",
        "\n",
        "    def __add__(self, other):\n",
        "        assert self.D == other.D\n",
        "        assert self.M == other.M\n",
        "        newfilter = self.copy()\n",
        "        for kk in self.keys:\n",
        "            newfilter.data[kk] = newfilter.data[kk] + other.data[kk]\n",
        "        return newfilter\n",
        "\n",
        "    def times_group_element(self, gg):\n",
        "        newfilter = self.copy()\n",
        "        for pp, kk in zip(self.pixels, self.keys):\n",
        "            newfilter.data[kk] = self.data[tuple(gg.T @ pp)].times_group_element(gg)\n",
        "        return newfilter\n",
        "\n",
        "    def unpack(self):\n",
        "        return np.array([self.data[kk].data for kk in self.keys])"
      ],
      "metadata": {
        "id": "2z4tzfDa61KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxMRi3VjD_zN"
      },
      "outputs": [],
      "source": [
        "# Visualize (badly) a scalar filter.\n",
        "\n",
        "FIGSIZE = (4, 3)\n",
        "XOFF, YOFF = 0.15, -0.1\n",
        "TINY = 1.e-5\n",
        "\n",
        "def setup_plot():\n",
        "    fig = plt.figure(figsize=FIGSIZE)\n",
        "\n",
        "def finish_plot(title, pixels):\n",
        "    plt.title(title)\n",
        "    if D == 2:\n",
        "        plt.xlim(np.min(pixels)-0.5, np.max(pixels)+0.5)\n",
        "        plt.ylim(np.min(pixels)-0.5, np.max(pixels)+0.5)\n",
        "    if D == 3:\n",
        "        plt.xlim(np.min(pixels)-0.75, np.max(pixels)+0.75)\n",
        "        plt.ylim(np.min(pixels)-0.75, np.max(pixels)+0.75)\n",
        "    plt.gca().set_aspect(\"equal\")\n",
        "    plt.gca().set_xticks([])\n",
        "    plt.gca().set_yticks([])\n",
        "\n",
        "def plot_boxes(xs, ys):\n",
        "    for x, y in zip(xs, ys):\n",
        "        plt.plot([x-0.5, x-0.5, x+0.5, x+0.5, x-0.5],\n",
        "                 [y-0.5, y+0.5, y+0.5, y-0.5, y-0.5], \"k-\", lw=0.5)\n",
        "\n",
        "def fill_boxes(xs, ys, ws):\n",
        "    for x, y, w in zip(xs, ys, ws):\n",
        "        if np.abs(w) > TINY:\n",
        "            plt.fill_between([x - 0.5, x + 0.5], [y - 0.5, y - 0.5], [y + 0.5, y + 0.5],\n",
        "                             color=\"k\", alpha=0.1 * np.abs(w))\n",
        "\n",
        "def plot_scalars(xs, ys, ws):\n",
        "    plot_boxes(xs, ys)\n",
        "    fill_boxes(xs, ys, ws)\n",
        "    plt.scatter(xs[ws > TINY], ys[ws > TINY], marker=\"+\", c=\"k\", s=(1000/M)*ws[ws > TINY])\n",
        "    plt.scatter(xs[ws < TINY], ys[ws < TINY], marker=\"_\", c=\"k\", s=(-1000/M)*ws[ws < TINY])\n",
        "\n",
        "def plot_scalar_filter(filter, title):\n",
        "    assert filter.k == 0\n",
        "    if filter.D not in [2, 3]:\n",
        "        print(\"plot_scalar_filter(): Only works for D in [2, 3].\")\n",
        "        return\n",
        "    setup_plot()\n",
        "    MtotheD = filter.M ** filter.D\n",
        "    xs, ys, zs = np.zeros(MtotheD), np.zeros(MtotheD), np.zeros(MtotheD)\n",
        "    ws = np.zeros(MtotheD)\n",
        "    if filter.D == 2:\n",
        "        for i, (kk, pp) in enumerate(zip(filter.keys, filter.pixels)):\n",
        "            xs[i], ys[i] = pp\n",
        "            ws[i] = filter.data[kk].data\n",
        "        plot_scalars(xs, ys, ws)\n",
        "    if filter.D == 3:\n",
        "        for i, (kk, pp) in enumerate(zip(filter.keys, filter.pixels)):\n",
        "            xs[i], ys[i], zs[i] = pp\n",
        "            ws[i] = filter.data[kk].data\n",
        "        plot_scalars(xs + XOFF * zs, ys + YOFF * zs, ws)\n",
        "    finish_plot(title, filter.pixels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "foo = geometric_filter(np.random.normal(size=9), 1)\n",
        "plot_scalar_filter(foo, \"foo\")\n",
        "for i, gg in enumerate(group_operators):\n",
        "    plot_scalar_filter(foo.times_group_element(gg), \"$g_{}\\cdot$foo\".format(i))"
      ],
      "metadata": {
        "id": "QmQQUQoGnC2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYXICGwCHFTi"
      },
      "outputs": [],
      "source": [
        "# Visualize the vector filters.\n",
        "\n",
        "def plot_vectors(xs, ys, ws):\n",
        "    plot_boxes(xs, ys)\n",
        "    fill_boxes(xs, ys, np.sum(np.abs(ws), axis=-1))\n",
        "    for x, y, w in zip(xs, ys, ws):\n",
        "        if np.sum(w * w) > TINY:\n",
        "            plt.arrow(x - 0.3 * w[0], y - 0.3 * w[1],\n",
        "                      0.6 * w[0], 0.6 * w[1],\n",
        "                      length_includes_head=True, head_width=0.1, color=\"k\")\n",
        "\n",
        "def plot_vector_filter(filter, title):\n",
        "    assert filter.k == 1\n",
        "    if filter.D not in [2, 3]:\n",
        "        print(\"plot_vector_filter(): Only works for D in [2, 3].\")\n",
        "        return\n",
        "    setup_plot()\n",
        "    MtotheD = filter.M ** filter.D\n",
        "    xs, ys, zs = np.zeros(MtotheD), np.zeros(MtotheD), np.zeros(MtotheD)\n",
        "    ws = np.zeros((MtotheD, filter.D))\n",
        "    if filter.D == 2:\n",
        "        for i, (kk, pp) in enumerate(zip(filter.keys, filter.pixels)):\n",
        "            xs[i], ys[i] = pp\n",
        "            ws[i] = filter.data[kk].data\n",
        "        plot_vectors(xs, ys, ws)\n",
        "    if filter.D == 3:\n",
        "        for i, (kk, pp) in enumerate(zip(filter.keys, filter.pixels)):\n",
        "            xs[i], ys[i], zs[i] = pp\n",
        "            ws[i] = filter.data[kk].data\n",
        "        plot_vectors(xs + XOFF * zs, ys + YOFF * zs, ws)\n",
        "    finish_plot(title, filter.pixels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "foo = geometric_filter(np.random.normal(size=(9,2)), 1)\n",
        "plot_vector_filter(foo, \"foo\")\n",
        "for i, gg in enumerate(group_operators):\n",
        "    s, l = np.linalg.slogdet(gg)\n",
        "    if s > 0:\n",
        "        plot_vector_filter(foo.times_group_element(gg), \"$g_{}\\cdot$foo\".format(i))"
      ],
      "metadata": {
        "id": "U5o7keM-sTY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now start the process of making the invariant filters"
      ],
      "metadata": {
        "id": "3z3bM0xSm_ls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSy3X7eJjsFX"
      },
      "outputs": [],
      "source": [
        "# Make geometric filter manipulation functions\n",
        "\n",
        "def make_zero_filter(k, parity):\n",
        "    data = np.zeros((M ** D, ) + k * (D, ))\n",
        "    return geometric_filter(data, parity, D)\n",
        "\n",
        "def rotate_vector(filter, gg, parity=1):\n",
        "    return rotate(filter, gg)\n",
        "    newfilter = filter.copy()\n",
        "    for pp, kk in zip(pixels, keys):\n",
        "        newfilter[kk] = gg @ filter[hash(gg.T @ pp)]\n",
        "    if parity < 0:\n",
        "        return scalar_multiply(np.linalg.slogdet(gg)[0], newfilter)\n",
        "    return newfilter\n",
        "\n",
        "def rotate_pseudovector(filter, gg):\n",
        "    return rotate_vector(filter, gg, -1)\n",
        "\n",
        "def rotate_2_tensor(filter, gg, parity=1):\n",
        "    newfilter = filter.copy()\n",
        "    for pp, kk in zip(pixels, keys):\n",
        "        newfilter[kk] = gg @ filter[hash(gg.T @ pp)] @ gg.T\n",
        "    if parity < 0:\n",
        "        return scalar_multiply(np.linalg.slogdet(gg)[0], newfilter)\n",
        "    return newfilter\n",
        "\n",
        "def scalar_multiply(scalar, filter):\n",
        "    newfilter = filter.copy()\n",
        "    for kk in keys:\n",
        "        newfilter[kk] = scalar * filter[kk]\n",
        "    return newfilter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u4cdg5ihcft"
      },
      "outputs": [],
      "source": [
        "# Make nxn independent scalar-to-scalar filters\n",
        "keys = make_zero_filter(0, 1).keys\n",
        "allfilters = []\n",
        "for kk in keys:\n",
        "    thisfilter = make_zero_filter(0, 1)\n",
        "    thisfilter.data[kk].data = 1\n",
        "    allfilters.append(thisfilter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjiTfZdCkjPw"
      },
      "outputs": [],
      "source": [
        "# Sum all the group-element-transformed scalar filters and make a matrix of them\n",
        "n = len(allfilters)\n",
        "filter_matrix = np.zeros((n, n)).astype(int)\n",
        "for i, f1 in enumerate(allfilters):\n",
        "    ff = make_zero_filter(0, 1)\n",
        "    for gg in group_operators:\n",
        "        ff = ff + f1.times_group_element(gg)\n",
        "    filter_matrix[i] = ff.unpack()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPOirFX7na-w"
      },
      "outputs": [],
      "source": [
        "# What are the unique scalar filters?\n",
        "def get_unique_filters(k, parity):\n",
        "    # make the seed filters\n",
        "    keys = make_zero_filter(k, parity).keys\n",
        "    allfilters = []\n",
        "    if k == 0:\n",
        "        for kk in keys:\n",
        "            thisfilter = make_zero_filter(k, parity)\n",
        "            thisfilter.data[kk].data = 1\n",
        "            allfilters.append(thisfilter)\n",
        "    else:\n",
        "        for kk in keys:\n",
        "            thisfilter = make_zero_filter(k, parity)\n",
        "            for indices in something:\n",
        "                thisfilter.data[kk].data[indices] = 1\n",
        "                allfilters.append(thisfilter)\n",
        "    # do the group averaging\n",
        "    shape = (len(allfilters), ) + thisfilter.unpack().shape # THIS LINE IS WRONG\n",
        "    filter_matrix = np.zeros(shape)\n",
        "    for i, f1 in enumerate(allfilters):\n",
        "        ff = make_zero_filter(k, parity)\n",
        "        for gg in group_operators:\n",
        "            ff = ff + f1.times_group_element(gg)\n",
        "        filter_matrix[i] = ff.unpack()\n",
        "    # do the SVD\n",
        "    u, s, v = np.linalg.svd(filter_matrix)\n",
        "    TINY = 1.e-5\n",
        "    sbig = s > TINY\n",
        "    if not np.any(sbig):\n",
        "        return []\n",
        "    # normalize the amplitudes so they max out at +/- 1.\n",
        "    amps = v[sbig] / np.max(np.abs(v[sbig]), axis=1)[:, None]\n",
        "    # make sure the amps are positive, generally\n",
        "    for i in range(len(amps)):\n",
        "        if np.sum(amps[i]) < 0:\n",
        "            amps[i] *= -1\n",
        "    # make sure that the zeros are zeros.\n",
        "    amps[np.abs(amps) < TINY] = 0.\n",
        "    return [geometric_filter(aa, parity) for aa in amps]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar_filters = get_unique_filters(0, 1)\n",
        "for i, ff in enumerate(scalar_filters):\n",
        "    plot_scalar_filter(ff, \"scalar {}\".format(i))"
      ],
      "metadata": {
        "id": "VE4_gBvJTslZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pseudoscalar_filters = get_unique_filters(0, -1)\n",
        "for i, ff in enumerate(pseudoscalar_filters):\n",
        "    plot_scalar_filter(ff, \"pseudoscalar {}\".format(i))"
      ],
      "metadata": {
        "id": "a7o2odmIWwi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfNYOF9DoaKz"
      },
      "outputs": [],
      "source": [
        "# Make Dn x Dn x ... independent scalar-to-vector filters\n",
        "allvfilters = []\n",
        "for kk in keys:\n",
        "    for i in range(D):\n",
        "        thisfilter = make_zero_vector_filter()\n",
        "        thisfilter[kk][i] = 1\n",
        "        allvfilters.append(thisfilter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfh9XBhXrkgl"
      },
      "outputs": [],
      "source": [
        "# Sum all the group-element-tranformed scalar-to-vector filters and make a matrix of them\n",
        "n = len(allvfilters)\n",
        "vfilter_matrix = np.zeros((n, n)).astype(int)\n",
        "for i, f1 in enumerate(allvfilters):\n",
        "    ff = make_zero_vector_filter()\n",
        "    for gg in group_operators:\n",
        "        ff = add(ff, rotate_vector(f1, gg))\n",
        "    vfilter_matrix[i] = unpack_vector_filter(ff).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIdDZFntthWo"
      },
      "outputs": [],
      "source": [
        "# What are the unique scalar-to-vector filters?\n",
        "def get_unique_vector_filters(matrix, parity):\n",
        "    u, s, v = np.linalg.svd(matrix)\n",
        "    TINY = 1.e-5\n",
        "    sbig = s > TINY\n",
        "    if not np.any(sbig):\n",
        "        return []\n",
        "    nbig = np.sum(sbig).astype(int)\n",
        "    vecs = v[sbig].reshape((nbig, M ** D, D))\n",
        "    # normalize so the biggest vectors are unit vectors\n",
        "    for i in range(nbig):\n",
        "        vecs[i] /= np.max([np.linalg.norm(vv) for vv in vecs[i]])\n",
        "    # make sure the divergences or curls are positive\n",
        "    if parity > 0:\n",
        "        for i in range(nbig):\n",
        "            if np.sum(vecs[i] * pixels) < 0:\n",
        "                vecs[i] *= -1\n",
        "    if D == 2 and parity < 0:\n",
        "        rpixels = np.zeros_like(pixels)\n",
        "        rpixels[:, 0], rpixels[:, 1] = -1. * pixels[:, 1], pixels[:, 0]\n",
        "        for i in range(nbig):\n",
        "            if np.sum(vecs[i] * rpixels) < 0:\n",
        "                vecs[i] *= -1\n",
        "    # make sure zeros are exactly zero\n",
        "    vecs[np.abs(vecs) < TINY] = 0.0\n",
        "    return order_filters([pack_vector_filter(vv) for vv in vecs])\n",
        "\n",
        "vfilters = get_unique_vector_filters(vfilter_matrix, 1)\n",
        "for ff in vfilters:\n",
        "    print(ff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC5l_2-juOLJ"
      },
      "outputs": [],
      "source": [
        "# Sum all the group-element-tranformed scalar-to-pseudovector filters and make a matrix of them\n",
        "n = len(allvfilters)\n",
        "pvfilter_matrix = np.zeros((n, n)).astype(int)\n",
        "for i, f1 in enumerate(allvfilters):\n",
        "    ff = make_zero_vector_filter()\n",
        "    for gg in group_operators:\n",
        "        ff = add(ff, rotate_pseudovector(f1, gg))\n",
        "    pvfilter_matrix[i] = unpack_vector_filter(ff).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCTAXD0nDukV"
      },
      "outputs": [],
      "source": [
        "# What are the unique scalar-to-pseudovector filters?\n",
        "pvfilters = get_unique_vector_filters(pvfilter_matrix, -1)\n",
        "for ff in pvfilters:\n",
        "    print(ff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3F8_xbTD08H"
      },
      "outputs": [],
      "source": [
        "# Visualize (badly) the pseudovector filters.\n",
        "for i, ff in enumerate(pvfilters):\n",
        "    plot_vector_filter(ff, \"pseudovector \" + str(i))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Dn x Dn x ... independent scalar-to-vector filters\n",
        "allttfilters = []\n",
        "for kk in keys:\n",
        "    for i,j in it.product(range(D), repeat=2):\n",
        "        thisfilter = make_zero_2_tensor_filter()\n",
        "        thisfilter[kk][i, j] = 1\n",
        "        allttfilters.append(thisfilter)"
      ],
      "metadata": {
        "id": "jMzsREVwVZpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum all the group-element-tranformed scalar-to-vector filters and make a matrix of them\n",
        "n = len(allttfilters)\n",
        "ttfilter_matrix = np.zeros((n, n)).astype(int)\n",
        "for i, f1 in enumerate(allttfilters):\n",
        "    ff = make_zero_2_tensor_filter()\n",
        "    for gg in group_operators:\n",
        "        ff = add(ff, rotate_2_tensor(f1, gg))\n",
        "    ttfilter_matrix[i] = unpack_2_tensor_filter(ff).flatten()"
      ],
      "metadata": {
        "id": "xIpDm0pnWfZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the unique scalar-to-vector filters?\n",
        "def get_unique_2_tensor_filters(matrix, parity):\n",
        "    u, s, v = np.linalg.svd(matrix)\n",
        "    TINY = 1.e-5\n",
        "    sbig = s > TINY\n",
        "    if not np.any(sbig):\n",
        "        return []\n",
        "    nbig = np.sum(sbig).astype(int)\n",
        "    tens = v[sbig].reshape((nbig, M ** D, D, D))\n",
        "    # change signs so the tensors are largely positive\n",
        "    for i in range(nbig):\n",
        "        tracesum = np.sum([np.trace(tt) for tt in tens[i]])\n",
        "        if tracesum < 0:\n",
        "            tens[i] *= -1.\n",
        "    # normalize so the largest tensors are unit tensors\n",
        "    for i in range(nbig):\n",
        "        tens[i] /= np.max([np.linalg.norm(tt, ord=2) for tt in tens[i]])\n",
        "    # make sure zeros are exactly zero\n",
        "    tens[np.abs(tens) < TINY] = 0.0\n",
        "    # check whether they are hermitian?\n",
        "    for i in range(nbig):\n",
        "        print(i, [int(np.allclose(tt, tt.T)) for tt in tens[i]])\n",
        "    return order_filters([pack_2_tensor_filter(tt) for tt in tens])\n",
        "\n",
        "ttfilters = get_unique_2_tensor_filters(ttfilter_matrix, 1)\n",
        "# for ff in ttfilters:\n",
        "#     print(ff)"
      ],
      "metadata": {
        "id": "uVndP6NNW1m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the 2-tensor filters\n",
        "# HOGG TBD"
      ],
      "metadata": {
        "id": "j5LXiCaz2p5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPRDUz-_GdaR"
      },
      "source": [
        "# Now try convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFhj9ajnGiow"
      },
      "outputs": [],
      "source": [
        "# We need this to make fake data\n",
        "!pip install finufft\n",
        "import finufft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qqu5z7jGxnl"
      },
      "outputs": [],
      "source": [
        "# make a sensible smooth scalar image on a 2-torus\n",
        "N = 16\n",
        "np.random.seed(42)\n",
        "image = np.random.normal(size=(N, N))\n",
        "foo = np.pi * np.arange(-1. + 1. / N, 1., 2. / N)\n",
        "ys, xs = np.meshgrid(foo, foo) # ys, xs or xs, ys??\n",
        "ft = finufft.nufft2d1(xs.flatten(), ys.flatten(), image.flatten().astype(complex), (3, 3))\n",
        "scalar_image = finufft.nufft2d2(xs.flatten(), ys.flatten(), ft).reshape(N, N).real\n",
        "scalar_image /= np.sqrt(np.mean(scalar_image ** 2))\n",
        "print(scalar_image.shape, ft.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsePU4USIk9O"
      },
      "outputs": [],
      "source": [
        "plt.imshow(scalar_image, interpolation=\"nearest\", origin=\"lower\", cmap=\"gray\")\n",
        "plt.title(\"scalar image\")\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS-TFCl9JQEf"
      },
      "outputs": [],
      "source": [
        "# Make a sensible smooth vector image on a 2-torus\n",
        "np.random.seed(42)\n",
        "imagex = np.random.normal(size=(N, N))\n",
        "imagey = np.random.normal(size=(N, N))\n",
        "ftx = finufft.nufft2d1(xs.flatten(), ys.flatten(), imagex.flatten().astype(complex), (3, 3))\n",
        "fty = finufft.nufft2d1(xs.flatten(), ys.flatten(), imagey.flatten().astype(complex), (3, 3))\n",
        "vector_image = np.zeros((N, N, 2))\n",
        "vector_image[:, :, 0] = finufft.nufft2d2(xs.flatten(), ys.flatten(), ftx).reshape(N, N).real\n",
        "vector_image[:, :, 1] = finufft.nufft2d2(xs.flatten(), ys.flatten(), fty).reshape(N, N).real\n",
        "vector_image /= np.sqrt(np.mean(vector_image ** 2))\n",
        "print(vector_image.shape, ftx.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pxs, pys = np.meshgrid(np.arange(N), np.arange(N))\n",
        "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
        "plt.quiver(pxs.flatten(), pys.flatten(),\n",
        "           vector_image[:, :, 0].flatten(), vector_image[:, :, 1].flatten())\n",
        "plt.xlim(-0.5, N-0.5)\n",
        "plt.ylim(-0.5, N-0.5)\n",
        "plt.title(\"vector image\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j_VU7tABww0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now turn this into D-dimensional data in the D=3 case\n",
        "assert D in [2, 3]\n",
        "if D == 3:\n",
        "    foo, bar = scalar_image, vector_image\n",
        "    scalar_image = np.zeros((N, ) * D)\n",
        "    vector_image = np.zeros((N, ) * D + (D, ))\n",
        "    scalar_image = foo[:, :, None]\n",
        "    vector_image = bar[:, :, None, :]"
      ],
      "metadata": {
        "id": "Mn_n_c7tm_V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make d-torus convolution operator\n",
        "\n",
        "def reformat_filter_into_block(filter):\n",
        "    \"\"\"\n",
        "    ## bugs:\n",
        "    - This function should learn D, M, m, kprime from the filter.\n",
        "    - In general there are way too many global variables!\n",
        "    \"\"\"\n",
        "    m = (M - 1) // 2\n",
        "    assert M == 2 * m + 1\n",
        "    if len(np.atleast_1d(filter[keys[0]])) == 1:\n",
        "        kprime = 0\n",
        "    else:\n",
        "        kprime = len(filter[keys[0]].shape)\n",
        "    filtershape = (M, ) * D\n",
        "    filtershape += (D, ) * kprime\n",
        "    ff = np.zeros(filtershape)\n",
        "    for pp, kk in zip(pixels, keys):\n",
        "        ff[pp + m] = filter[kk]\n",
        "    return ff\n",
        "\n",
        "def geometric_convolve_torus(image, filter):\n",
        "    \"\"\"\n",
        "    ## bugs:\n",
        "    - Things in this code will not scale to big problems!\n",
        "    - Barely tested.\n",
        "    - Never tested on 2-tensors or higher.\n",
        "    \"\"\"\n",
        "    # check all inputs\n",
        "    Ns = image.shape[:D]\n",
        "    k = len(image.shape) - D\n",
        "    assert len(filter) == M ** D\n",
        "    assert M % 2 == 1\n",
        "    m = (M - 1) // 2\n",
        "    C = reformat_filter_into_block(filter)\n",
        "    kprime = len(C.shape) - D\n",
        "    # make output array\n",
        "    outshape = image.shape + (D, ) * kprime\n",
        "    outimage = np.zeros(outshape)\n",
        "    # this loops over all image pixels\n",
        "    for ii in it.product(*(range(N) for N in Ns)):\n",
        "        # this loops over all filter pixels\n",
        "        for jj in it.product(*(range(-m, m+1) for N in Ns)):\n",
        "            # this handles the torus wrapping\n",
        "            ll = tuple((i - j) % N for i, j, N in zip(ii, jj, Ns))\n",
        "            # this makes the filter index correctly\n",
        "            oo = tuple(j + m for j in jj)\n",
        "            # this performs a safe outer product\n",
        "            outimage[ii] += np.multiply.outer(image[ll], C[oo])\n",
        "    return outimage"
      ],
      "metadata": {
        "id": "jSZgWiSTT_F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now plot convlutions of images with filters\n",
        "# - for example: \"(scalar image) \\star (pseudovector 0)\"\n",
        "sstarv = geometric_convolve_torus(scalar_image, vfilters[1])\n",
        "sstars = geometric_convolve_torus(scalar_image, filters[0])\n",
        "vstars = geometric_convolve_torus(vector_image, filters[0])\n",
        "vstarv = geometric_convolve_torus(vector_image, vfilters[1])\n",
        "if len(pvfilters) > 0:\n",
        "    vstarpv = geometric_convolve_torus(vector_image, pvfilters[1])"
      ],
      "metadata": {
        "id": "T-FKunLZx2M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
        "plt.imshow(scalar_image, origin=\"lower\")\n",
        "plt.quiver(pxs.flatten(), pys.flatten(),\n",
        "           sstarv[:, :, 0].flatten(), sstarv[:, :, 1].flatten(),\n",
        "           color=\"r\")\n",
        "plt.xlim(-0.5, N-0.5)\n",
        "plt.ylim(-0.5, N-0.5)\n",
        "plt.title(\"scalar image STAR vector filter\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KD1X3NWY0j8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now show a nonlinear, local, scalar function of the scalar image\n",
        "plt.imshow(np.sum(sstarv * sstarv, axis=-1), origin=\"lower\")\n",
        "plt.title(\"squared norm of the above vectors\")"
      ],
      "metadata": {
        "id": "VKnKaltAyzDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
        "plt.imshow(vstarv[:, :, 0, 0] + vstarv[:, :, 1, 1], origin=\"lower\")\n",
        "plt.quiver(pxs.flatten(), pys.flatten(),\n",
        "           vector_image[:, :, 0].flatten(), vector_image[:, :, 1].flatten(),\n",
        "           color=\"r\")\n",
        "plt.xlim(-0.5, N-0.5)\n",
        "plt.ylim(-0.5, N-0.5)\n",
        "plt.title(\"vec image STAR vec filter, contracted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1fuByo5S8xSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
        "plt.imshow(vstarpv[:, :, 0, 0] + vstarpv[:, :, 1, 1], origin=\"lower\")\n",
        "plt.quiver(pxs.flatten(), pys.flatten(),\n",
        "           vector_image[:, :, 0].flatten(), vector_image[:, :, 1].flatten(),\n",
        "           color=\"r\")\n",
        "plt.xlim(-0.5, N-0.5)\n",
        "plt.ylim(-0.5, N-0.5)\n",
        "plt.title(\"vec image STAR pvec filter, contracted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ANMdmGVnB_h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EC9b9xxh2aXI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "group_averaging.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}