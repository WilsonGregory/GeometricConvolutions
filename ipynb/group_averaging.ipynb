{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidwhogg/EmuCosmoSim/blob/main/ipynb/group_averaging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGB_OA6Cvlah"
      },
      "source": [
        "# Finding equivariant convolution operators by group averaging\n",
        "\n",
        "## Authors:\n",
        "- **David W. Hogg** (NYU) (Flatiron)\n",
        "- **Soledad Villar** (JHU)\n",
        "\n",
        "## License\n",
        "Copyright 2022 the authors. All rights reserved *for now*.\n",
        "\n",
        "## To-do\n",
        "- Make structure so the code is agnostic about scalar/vector/tensor? That is, such that the objects know their own transformation properties? And norms? And visualization methods?\n",
        "\n",
        "## Bugs:\n",
        "- This code transmits `D, M, pixels, keys` as global variables, not by reading them off inputs (or getting them as inputs).\n",
        "- Haven't figured out yet how to visualize the 2-tensor filters; maybe plot eigenvalues and eigenvectors?\n",
        "- The group operators should be found by recursion; this ought to be more efficient.\n",
        "- Fix 3-d plotting so it does a real projection (not just a set of incomprehensible hacks)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q52E4gJ8UfGG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pylab as plt\n",
        "import itertools as it\n",
        "import scipy.signal as sig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yP10B3wza7FO"
      },
      "outputs": [],
      "source": [
        "# Set integers:\n",
        "D = 2 # D-dimensional image (must be 2 or 3 for plotting to work)\n",
        "M = 3 # must be an odd integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a09Z4sTfU01k"
      },
      "outputs": [],
      "source": [
        "# Make all n x n pixels\n",
        "if M % 2 != 1:\n",
        "    print(\"Filter size must be odd\")\n",
        "    assert False\n",
        "foo = range(-((M - 1) // 2), ((M + 1) // 2))\n",
        "pixels = np.array([pp for pp in it.product(foo, repeat=D)]).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHIAWe8-hEie"
      },
      "outputs": [],
      "source": [
        "# Define hash and unhash functions for pixel names\n",
        "def hash(pp):\n",
        "    return str(pp.astype(int))[1:-1]\n",
        "\n",
        "def unhash(kk):\n",
        "    return np.fromstring(kk, sep=\" \").astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up-16BM7K1NT"
      },
      "outputs": [],
      "source": [
        "# Make all keys\n",
        "keys = [hash(pp) for pp in pixels]\n",
        "print(keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fvi8Vw0Z6mFh"
      },
      "outputs": [],
      "source": [
        "# Make all possible group generators\n",
        "\n",
        "# Make the flip operator\n",
        "foo = np.ones(D).astype(int)\n",
        "foo[0] = -1\n",
        "gg = np.diag(foo).astype(int)\n",
        "generators = [gg, ]\n",
        "\n",
        "# Make the 90-degree rotation operators\n",
        "for i in range(D):\n",
        "    for j in range(i + 1, D):\n",
        "        gg = np.eye(D).astype(int)\n",
        "        gg[i, i] = 0\n",
        "        gg[j, j] = 0\n",
        "        gg[i, j] = -1\n",
        "        gg[j, i] = 1\n",
        "        generators.append(gg)\n",
        "generators = np.array(generators)\n",
        "\n",
        "# Look at them\n",
        "for gg in generators:\n",
        "    print(gg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXUqQpE8VlAy"
      },
      "outputs": [],
      "source": [
        "# Make all possible group operators.\n",
        "# This code is very wasteful; there is a better way with recursion.\n",
        "\n",
        "def make_all_operators(generators):\n",
        "    operators = np.array([np.eye(D).astype(int), ])\n",
        "    foo = 0\n",
        "    while len(operators) != foo:\n",
        "        foo = len(operators)\n",
        "        operators = make_new_operators(operators, generators)\n",
        "    return(operators)\n",
        "\n",
        "def make_new_operators(operators, generators):\n",
        "    for op in operators:\n",
        "        for gg in generators:\n",
        "            op2 = (gg @ op).astype(int)\n",
        "            operators = np.unique(np.append(operators, op2[None, :, :], axis=0), axis=0)\n",
        "    return operators\n",
        "\n",
        "group_operators = make_all_operators(generators)\n",
        "print(\"I found\", len(group_operators), \"group operators; here are their determinants:\")\n",
        "for gg in group_operators:\n",
        "    print(gg, \"determinant:\", np.linalg.slogdet(gg)[0].astype(int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bppoRi9_YQGP"
      },
      "outputs": [],
      "source": [
        "# Check that each group operator leaves the pixel list unchanged\n",
        "for gg in group_operators:\n",
        "    newpixels = np.array([gg @ pp.copy() for pp in pixels]).astype(int)\n",
        "    assert(set(tuple(pp) for pp in newpixels) == set(tuple(pp) for pp in pixels))\n",
        "    print(gg, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n960Qo6yY2p5"
      },
      "outputs": [],
      "source": [
        "# Check that the list of group operators is closed\n",
        "for gg in group_operators:\n",
        "    for gg2 in group_operators:\n",
        "        assert ((gg @ gg2).astype(int) in group_operators)\n",
        "    print(gg, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uC_pQ6kLqtR"
      },
      "outputs": [],
      "source": [
        "# Check that gg.T is gg.inv for all gg in group?\n",
        "for gg in group_operators:\n",
        "    print(gg, np.allclose(gg @ gg.T, np.eye(D)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSy3X7eJjsFX"
      },
      "outputs": [],
      "source": [
        "# Make filter manipulation functions\n",
        "\n",
        "def rotate_scalar(filter, gg, parity=1):\n",
        "    newfilter = filter.copy()\n",
        "    for pp, kk in zip(pixels, keys):\n",
        "        newfilter[kk] = filter[hash(gg.T @ pp)]\n",
        "    if parity < 0:\n",
        "        return scalar_multiply(np.linalg.slogdet(gg)[0], newfilter)\n",
        "    return newfilter\n",
        "\n",
        "def rotate_pseudoscalar(filter, gg):\n",
        "    return rotate_scalar(filter, gg, -1)\n",
        "\n",
        "def rotate_vector(filter, gg, parity=1):\n",
        "    newfilter = filter.copy()\n",
        "    for pp, kk in zip(pixels, keys):\n",
        "        newfilter[kk] = gg @ filter[hash(gg.T @ pp)]\n",
        "    if parity < 0:\n",
        "        return scalar_multiply(np.linalg.slogdet(gg)[0], newfilter)\n",
        "    return newfilter\n",
        "\n",
        "def rotate_pseudovector(filter, gg):\n",
        "    return rotate_vector(filter, gg, -1)\n",
        "\n",
        "def rotate_2_tensor(filter, gg, parity=1):\n",
        "    newfilter = filter.copy()\n",
        "    for pp, kk in zip(pixels, keys):\n",
        "        newfilter[kk] = gg @ filter[hash(gg.T @ pp)] @ gg.T\n",
        "    if parity < 0:\n",
        "        return scalar_multiply(np.linalg.slogdet(gg)[0], newfilter)\n",
        "    return newfilter\n",
        "\n",
        "def add(filter1, filter2):\n",
        "    newfilter = filter1.copy()\n",
        "    for kk in keys:\n",
        "        newfilter[kk] = filter1[kk] + filter2[kk]\n",
        "    return newfilter\n",
        "\n",
        "def scalar_multiply(scalar, filter):\n",
        "    newfilter = filter.copy()\n",
        "    for kk in keys:\n",
        "        newfilter[kk] = scalar * filter[kk]\n",
        "    return newfilter\n",
        "\n",
        "def pack_scalar_filter(amps):\n",
        "    assert len(amps) == M ** D\n",
        "    return {kk: ff for kk, ff in zip(keys, amps)}\n",
        "\n",
        "def unpack_scalar_filter(filter):\n",
        "    return np.array([filter[kk] for kk in keys])\n",
        "\n",
        "def make_zero_scalar_filter():\n",
        "    return pack_scalar_filter(np.zeros(M ** D).astype(int))\n",
        "\n",
        "def pack_vector_filter(vecs):\n",
        "    assert len(vecs) == M ** D\n",
        "    return {kk: ff for kk, ff in zip(keys, vecs)}\n",
        "\n",
        "def unpack_vector_filter(filter):\n",
        "    return np.array([filter[kk] for kk in keys])\n",
        "\n",
        "def make_zero_vector_filter():\n",
        "    return pack_vector_filter(np.zeros((M ** D, D)).astype(int))\n",
        "\n",
        "def pack_2_tensor_filter(tens):\n",
        "    assert len(tens) == M ** D\n",
        "    return {kk: ff for kk, ff in zip(keys, tens)}\n",
        "\n",
        "def unpack_2_tensor_filter(filter):\n",
        "    return np.array([filter[kk] for kk in keys])\n",
        "\n",
        "def make_zero_2_tensor_filter():\n",
        "    return pack_vector_filter(np.zeros((M ** D, D, D)).astype(int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u4cdg5ihcft"
      },
      "outputs": [],
      "source": [
        "# Make nxn independent scalar-to-scalar filters\n",
        "allfilters = []\n",
        "for kk in keys:\n",
        "    thisfilter = make_zero_scalar_filter()\n",
        "    thisfilter[kk] = 1\n",
        "    allfilters.append(thisfilter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjiTfZdCkjPw"
      },
      "outputs": [],
      "source": [
        "# Sum all the group-element-transformed scalar-to-scalar filters and make a matrix of them\n",
        "n = len(allfilters)\n",
        "filter_matrix = np.zeros((n, n)).astype(int)\n",
        "for i, f1 in enumerate(allfilters):\n",
        "    ff = make_zero_scalar_filter()\n",
        "    for gg in group_operators:\n",
        "        ff = add(ff, rotate_scalar(f1, gg))\n",
        "    filter_matrix[i] = unpack_scalar_filter(ff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPOirFX7na-w"
      },
      "outputs": [],
      "source": [
        "# What are the unique scalar-to-scalar filters?\n",
        "def get_unique_scalar_filters(matrix):\n",
        "    u, s, v = np.linalg.svd(matrix)\n",
        "    TINY = 1.e-5\n",
        "    sbig = s > TINY\n",
        "    if not np.any(sbig):\n",
        "        return []\n",
        "    # normalize the ampltidues so they max out at +/- 1.\n",
        "    amps = v[sbig] / np.max(np.abs(v[sbig]), axis=1)[:, None]\n",
        "    # make sure the amps are positive, generally\n",
        "    for i in range(len(amps)):\n",
        "        if np.sum(amps[i]) < 0:\n",
        "            amps[i] *= -1\n",
        "    # make sure that the zeros are zeros.\n",
        "    amps[np.abs(amps) < TINY] = 0.\n",
        "    return order_filters([pack_scalar_filter(aa) for aa in amps])\n",
        "\n",
        "def filter_size(filter):\n",
        "    \"\"\"\n",
        "    What is the (squared) size of the filter footprint?\n",
        "    BUG: THIS WON'T WORK WELL FOR A TENSOR FILTER.\n",
        "    \"\"\"\n",
        "    foo, bar = 0., 0.\n",
        "    for pp, kk in zip(pixels, keys):\n",
        "        ww = np.linalg.norm(np.atleast_1d(filter[kk]), ord=2)\n",
        "        foo += np.linalg.norm(pp * ww)\n",
        "        bar += ww\n",
        "    return foo / bar\n",
        "\n",
        "def order_filters(filters):\n",
        "    \"\"\"\n",
        "    Order filters by size.\n",
        "    \"\"\"\n",
        "    sizes = [filter_size(ff) for ff in filters]\n",
        "    return [filters[ii] for ii in np.argsort(sizes)]\n",
        "\n",
        "filters = get_unique_scalar_filters(filter_matrix)\n",
        "for ff in filters:\n",
        "    print(ff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxMRi3VjD_zN"
      },
      "outputs": [],
      "source": [
        "# Visualize (badly) the scalar filters.\n",
        "\n",
        "FIGSIZE = (4, 3)\n",
        "XOFF, YOFF = 0.15, -0.1\n",
        "TINY = 1.e-5\n",
        "\n",
        "def setup_plot():\n",
        "    fig = plt.figure(figsize=FIGSIZE)\n",
        "\n",
        "def finish_plot(title):\n",
        "    plt.title(title)\n",
        "    if D == 2:\n",
        "        plt.xlim(np.min(pixels)-0.5, np.max(pixels)+0.5)\n",
        "        plt.ylim(np.min(pixels)-0.5, np.max(pixels)+0.5)\n",
        "    if D == 3:\n",
        "        plt.xlim(np.min(pixels)-0.75, np.max(pixels)+0.75)\n",
        "        plt.ylim(np.min(pixels)-0.75, np.max(pixels)+0.75)\n",
        "    plt.gca().set_aspect(\"equal\")\n",
        "\n",
        "def plot_boxes(xs, ys):\n",
        "    for x, y in zip(xs, ys):\n",
        "        plt.plot([x-0.5, x-0.5, x+0.5, x+0.5, x-0.5],\n",
        "                 [y-0.5, y+0.5, y+0.5, y-0.5, y-0.5], \"k-\", lw=0.5)\n",
        "\n",
        "def fill_boxes(xs, ys, ws):\n",
        "    for x, y, w in zip(xs, ys, ws):\n",
        "        if np.abs(w) > TINY:\n",
        "            plt.fill_between([x - 0.5, x + 0.5], [y - 0.5, y - 0.5], [y + 0.5, y + 0.5],\n",
        "                             color=\"k\", alpha=0.1)\n",
        "\n",
        "def plot_scalars(xs, ys, ws):\n",
        "    plot_boxes(xs, ys)\n",
        "    fill_boxes(xs, ys, ws)\n",
        "    plt.scatter(xs[ws > TINY], ys[ws > TINY], marker=\"+\", c=\"k\", s=(1000/M)*ws[ws > TINY])\n",
        "    plt.scatter(xs[ws < TINY], ys[ws < TINY], marker=\"_\", c=\"k\", s=(-1000/M)*ws[ws < TINY])\n",
        "\n",
        "def plot_scalar_filter(filter, title):\n",
        "    if D not in [2, 3]:\n",
        "        print(\"plot_scalar_filter(): Only works for D in [2, 3].\")\n",
        "        return\n",
        "    setup_plot()\n",
        "    xs, ys, zs = np.zeros(M ** D), np.zeros(M ** D), np.zeros(M ** D)\n",
        "    ws = np.zeros(M ** D)\n",
        "    if D == 2:\n",
        "        for i, kk in enumerate(keys):\n",
        "            xs[i], ys[i] = unhash(kk)\n",
        "            ws[i] = filter[kk]\n",
        "        plot_scalars(xs, ys, ws)\n",
        "    if D == 3:\n",
        "        for i, kk in enumerate(keys):\n",
        "            xs[i], ys[i], zs[i] = unhash(kk)\n",
        "            ws[i] = filter[kk]\n",
        "        plot_scalars(xs + XOFF * zs, ys + YOFF * zs, ws)\n",
        "    finish_plot(title)\n",
        "\n",
        "for i, ff in enumerate(filters):\n",
        "    plot_scalar_filter(ff, \"scalar \" + str(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Udu4DNuFKN5V"
      },
      "outputs": [],
      "source": [
        "# Sum all the group-element-tranformed scalar-to-pseudoscalar filters and make a matrix of them\n",
        "n = len(allfilters)\n",
        "pfilter_matrix = np.zeros((n, n)).astype(int)\n",
        "for i, f1 in enumerate(allfilters):\n",
        "    ff = make_zero_scalar_filter()\n",
        "    for gg in group_operators:\n",
        "        ff = add(ff, rotate_pseudoscalar(f1, gg))\n",
        "    pfilter_matrix[i] = unpack_scalar_filter(ff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGAUnX5eKsqN"
      },
      "outputs": [],
      "source": [
        "# What are the unique scalar-to-scalar filters?\n",
        "pfilters = get_unique_scalar_filters(pfilter_matrix)\n",
        "for ff in pfilters:\n",
        "    print(ff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPVqTycLKv9G"
      },
      "outputs": [],
      "source": [
        "# Visualize (badly) the pseudoscalar filters.\n",
        "for i, ff in enumerate(pfilters):\n",
        "    plot_scalar_filter(ff, \"pseudoscalar \" + str(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfNYOF9DoaKz"
      },
      "outputs": [],
      "source": [
        "# Make Dn x Dn x ... independent scalar-to-vector filters\n",
        "allvfilters = []\n",
        "for kk in keys:\n",
        "    for i in range(D):\n",
        "        thisfilter = make_zero_vector_filter()\n",
        "        thisfilter[kk][i] = 1\n",
        "        allvfilters.append(thisfilter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfh9XBhXrkgl"
      },
      "outputs": [],
      "source": [
        "# Sum all the group-element-tranformed scalar-to-vector filters and make a matrix of them\n",
        "n = len(allvfilters)\n",
        "vfilter_matrix = np.zeros((n, n)).astype(int)\n",
        "for i, f1 in enumerate(allvfilters):\n",
        "    ff = make_zero_vector_filter()\n",
        "    for gg in group_operators:\n",
        "        ff = add(ff, rotate_vector(f1, gg))\n",
        "    vfilter_matrix[i] = unpack_vector_filter(ff).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIdDZFntthWo"
      },
      "outputs": [],
      "source": [
        "# What are the unique scalar-to-vector filters?\n",
        "def get_unique_vector_filters(matrix, parity):\n",
        "    u, s, v = np.linalg.svd(matrix)\n",
        "    TINY = 1.e-5\n",
        "    sbig = s > TINY\n",
        "    if not np.any(sbig):\n",
        "        return []\n",
        "    nbig = np.sum(sbig).astype(int)\n",
        "    vecs = v[sbig].reshape((nbig, M ** D, D))\n",
        "    # normalize so the biggest vectors are unit vectors\n",
        "    for i in range(nbig):\n",
        "        vecs[i] /= np.max([np.linalg.norm(vv) for vv in vecs[i]])\n",
        "    # make sure the divergences or curls are positive\n",
        "    if parity > 0:\n",
        "        for i in range(nbig):\n",
        "            if np.sum(vecs[i] * pixels) < 0:\n",
        "                vecs[i] *= -1\n",
        "    if D == 2 and parity < 0:\n",
        "        rpixels = np.zeros_like(pixels)\n",
        "        rpixels[:, 0], rpixels[:, 1] = -1. * pixels[:, 1], pixels[:, 0]\n",
        "        for i in range(nbig):\n",
        "            if np.sum(vecs[i] * rpixels) < 0:\n",
        "                vecs[i] *= -1\n",
        "    # make sure zeros are exactly zero\n",
        "    vecs[np.abs(vecs) < TINY] = 0.0\n",
        "    return order_filters([pack_vector_filter(vv) for vv in vecs])\n",
        "\n",
        "vfilters = get_unique_vector_filters(vfilter_matrix, 1)\n",
        "for ff in vfilters:\n",
        "    print(ff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYXICGwCHFTi"
      },
      "outputs": [],
      "source": [
        "# Visualize the vector filters.\n",
        "\n",
        "def plot_vectors(xs, ys, ws):\n",
        "    plot_boxes(xs, ys)\n",
        "    fill_boxes(xs, ys, np.sum(np.abs(ws), axis=-1))\n",
        "    for x, y, w in zip(xs, ys, ws):\n",
        "        if np.sum(w * w) > TINY:\n",
        "            plt.arrow(x - 0.3 * w[0], y - 0.3 * w[1],\n",
        "                      0.6 * w[0], 0.6 * w[1],\n",
        "                      length_includes_head=True, head_width=0.1, color=\"k\")\n",
        "\n",
        "def plot_vector_filter(filter, title):\n",
        "    if D not in [2, 3]:\n",
        "        print(\"plot_vector_filter(): Only works for D in [2, 3].\")\n",
        "        return\n",
        "    setup_plot()\n",
        "    xs, ys, zs = np.zeros(M ** D), np.zeros(M ** D), np.zeros(M ** D)\n",
        "    ws = np.zeros((M ** D, D))\n",
        "    if D == 2:\n",
        "        for i, kk in enumerate(keys):\n",
        "            xs[i], ys[i] = unhash(kk)\n",
        "            ws[i] = filter[kk]\n",
        "        plot_vectors(xs, ys, ws)\n",
        "    if D == 3:\n",
        "        for i, kk in enumerate(keys):\n",
        "            xs[i], ys[i], zs[i] = unhash(kk)\n",
        "            ws[i] = filter[kk]\n",
        "        plot_vectors(xs + XOFF * zs, ys + YOFF * zs, ws)\n",
        "    finish_plot(title)\n",
        "\n",
        "for i, ff in enumerate(vfilters):\n",
        "    plot_vector_filter(ff, \"vector \" + str(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC5l_2-juOLJ"
      },
      "outputs": [],
      "source": [
        "# Sum all the group-element-tranformed scalar-to-pseudovector filters and make a matrix of them\n",
        "n = len(allvfilters)\n",
        "pvfilter_matrix = np.zeros((n, n)).astype(int)\n",
        "for i, f1 in enumerate(allvfilters):\n",
        "    ff = make_zero_vector_filter()\n",
        "    for gg in group_operators:\n",
        "        ff = add(ff, rotate_pseudovector(f1, gg))\n",
        "    pvfilter_matrix[i] = unpack_vector_filter(ff).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCTAXD0nDukV"
      },
      "outputs": [],
      "source": [
        "# What are the unique scalar-to-pseudovector filters?\n",
        "pvfilters = get_unique_vector_filters(pvfilter_matrix, -1)\n",
        "for ff in pvfilters:\n",
        "    print(ff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3F8_xbTD08H"
      },
      "outputs": [],
      "source": [
        "# Visualize (badly) the pseudovector filters.\n",
        "for i, ff in enumerate(pvfilters):\n",
        "    plot_vector_filter(ff, \"pseudovector \" + str(i))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Dn x Dn x ... independent scalar-to-vector filters\n",
        "allttfilters = []\n",
        "for kk in keys:\n",
        "    for i,j in it.product(range(D), repeat=2):\n",
        "        thisfilter = make_zero_2_tensor_filter()\n",
        "        thisfilter[kk][i, j] = 1\n",
        "        allttfilters.append(thisfilter)"
      ],
      "metadata": {
        "id": "jMzsREVwVZpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum all the group-element-tranformed scalar-to-vector filters and make a matrix of them\n",
        "n = len(allttfilters)\n",
        "ttfilter_matrix = np.zeros((n, n)).astype(int)\n",
        "for i, f1 in enumerate(allttfilters):\n",
        "    ff = make_zero_2_tensor_filter()\n",
        "    for gg in group_operators:\n",
        "        ff = add(ff, rotate_2_tensor(f1, gg))\n",
        "    ttfilter_matrix[i] = unpack_2_tensor_filter(ff).flatten()"
      ],
      "metadata": {
        "id": "xIpDm0pnWfZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the unique scalar-to-vector filters?\n",
        "def get_unique_2_tensor_filters(matrix, parity):\n",
        "    u, s, v = np.linalg.svd(matrix)\n",
        "    TINY = 1.e-5\n",
        "    sbig = s > TINY\n",
        "    if not np.any(sbig):\n",
        "        return []\n",
        "    nbig = np.sum(sbig).astype(int)\n",
        "    tens = v[sbig].reshape((nbig, M ** D, D, D))\n",
        "    # change signs so the tensors are largely positive\n",
        "    for i in range(nbig):\n",
        "        tracesum = np.sum([np.trace(tt) for tt in tens[i]])\n",
        "        if tracesum < 0:\n",
        "            tens[i] *= -1.\n",
        "    # normalize so the largest tensors are unit tensors\n",
        "    for i in range(nbig):\n",
        "        tens[i] /= np.max([np.linalg.norm(tt, ord=2) for tt in tens[i]])\n",
        "    # make sure zeros are exactly zero\n",
        "    tens[np.abs(tens) < TINY] = 0.0\n",
        "    # check whether they are hermitian?\n",
        "    for i in range(nbig):\n",
        "        assert np.all([np.allclose(tt, tt.T) for tt in tens[i]])\n",
        "    print(\"get_unique_2_tensor_filters(): everything Hermitian!\")\n",
        "    return order_filters([pack_2_tensor_filter(tt) for tt in tens])\n",
        "\n",
        "ttfilters = get_unique_2_tensor_filters(ttfilter_matrix, 1)\n",
        "for ff in ttfilters:\n",
        "    print(ff)"
      ],
      "metadata": {
        "id": "uVndP6NNW1m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the tensor filters\n",
        "# HOGG TBD"
      ],
      "metadata": {
        "id": "j5LXiCaz2p5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPRDUz-_GdaR"
      },
      "source": [
        "# Proceed no further unless D=2!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BiFan6gIxL8"
      },
      "outputs": [],
      "source": [
        "assert D == 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFhj9ajnGiow"
      },
      "outputs": [],
      "source": [
        "!pip install finufft\n",
        "import finufft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qqu5z7jGxnl"
      },
      "outputs": [],
      "source": [
        "# make a sensible smooth scalar image on a 2-torus\n",
        "N = 16\n",
        "np.random.seed(42)\n",
        "image = np.random.normal(size=(N, N))\n",
        "foo = np.pi * np.arange(-1. + 1. / N, 1., 2. / N)\n",
        "ys, xs = np.meshgrid(foo, foo) # ys, xs or xs, ys??\n",
        "ft = finufft.nufft2d1(xs.flatten(), ys.flatten(), image.flatten().astype(complex), (3, 3))\n",
        "scalar_image = finufft.nufft2d2(xs.flatten(), ys.flatten(), ft).reshape(N, N).real\n",
        "scalar_image /= np.sqrt(np.mean(scalar_image ** 2))\n",
        "print(scalar_image.shape, ft.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsePU4USIk9O"
      },
      "outputs": [],
      "source": [
        "plt.imshow(scalar_image, interpolation=\"nearest\", origin=\"lower\")\n",
        "plt.title(\"scalar image\")\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS-TFCl9JQEf"
      },
      "outputs": [],
      "source": [
        "# Make a sensible smooth vector image on a 2-torus\n",
        "np.random.seed(42)\n",
        "imagex = np.random.normal(size=(N, N))\n",
        "imagey = np.random.normal(size=(N, N))\n",
        "ftx = finufft.nufft2d1(xs.flatten(), ys.flatten(), imagex.flatten().astype(complex), (3, 3))\n",
        "fty = finufft.nufft2d1(xs.flatten(), ys.flatten(), imagey.flatten().astype(complex), (3, 3))\n",
        "vector_image = np.zeros((N, N, 2))\n",
        "vector_image[:, :, 0] = finufft.nufft2d2(xs.flatten(), ys.flatten(), ftx).reshape(N, N).real\n",
        "vector_image[:, :, 1] = finufft.nufft2d2(xs.flatten(), ys.flatten(), fty).reshape(N, N).real\n",
        "vector_image /= np.sqrt(np.mean(vector_image ** 2))\n",
        "print(vector_image.shape, ftx.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pxs, pys = np.meshgrid(np.arange(N), np.arange(N))\n",
        "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
        "plt.quiver(pxs.flatten(), pys.flatten(),\n",
        "           vector_image[:, :, 0].flatten(), vector_image[:, :, 1].flatten())\n",
        "plt.xlim(-0.5, N-0.5)\n",
        "plt.ylim(-0.5, N-0.5)\n",
        "plt.title(\"vector image\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j_VU7tABww0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make 2-torus convolution operator\n",
        "\n",
        "def convolve_2d_torus(image, filter):\n",
        "    \"\"\"\n",
        "    Warning: This code is stupid and brittle and dumb.\n",
        "    \"\"\"\n",
        "    # check all inputs\n",
        "    assert D == 2\n",
        "    Ny, Nx = image.shape[:2]\n",
        "    k = len(image.shape) - 2\n",
        "    M = np.round(np.sqrt(len(filter))).astype(int)\n",
        "    assert len(filter) == M * M\n",
        "    assert M % 2 == 1\n",
        "    # reformat filter into a block\n",
        "    pad = (M - 1) // 2\n",
        "    if len(np.atleast_1d(filter[keys[0]])) == 1:\n",
        "        kprime = 0\n",
        "    else:\n",
        "        kprime = len(filter[keys[0]].shape)\n",
        "    filtershape = (M, M)\n",
        "    for foo in range(kprime):\n",
        "        filtershape += (D, )\n",
        "    ff = np.zeros(filtershape)\n",
        "    for pp, kk in zip(pixels, keys):\n",
        "        ff[pp[1] + pad, pp[0] + pad] = filter[kk]\n",
        "    # kprime = SOMETHING\n",
        "    # pad out the image with copies\n",
        "    bigshape = [1 * foo for foo in image.shape]\n",
        "    bigshape[0] += 2 * pad\n",
        "    bigshape[1] += 2 * pad\n",
        "    bigimage = np.zeros(bigshape)\n",
        "    bigimage[pad:pad+Nx, pad:pad+Ny] = image\n",
        "    bigimage[:pad, pad:pad+Nx] = image[-pad:]\n",
        "    bigimage[-pad:, pad:pad+Nx] = image[:pad]\n",
        "    bigimage[pad:pad+Ny, :pad] = image[:, -pad:]\n",
        "    bigimage[pad:pad+Ny, -pad:] = image[:, :pad]\n",
        "    bigimage[:pad, :pad] = image[-pad:, -pad:]\n",
        "    bigimage[-pad:, :pad] = image[:pad, -pad:]\n",
        "    bigimage[:pad, -pad:] = image[-pad:, :pad]\n",
        "    bigimage[-pad:, -pad:] = image[:pad, :pad]\n",
        "    # make output array\n",
        "    outshape = image.shape + filtershape[2:]\n",
        "    outimage = np.zeros(outshape)\n",
        "    # reshape everyting and do the convolves\n",
        "    ff = ff.reshape((M, M, D ** kprime))\n",
        "    bigimage = bigimage.reshape((Ny + 2 * pad, Nx + 2 * pad, D ** k))\n",
        "    outimage = outimage.reshape(Ny, Nx, D ** (k + kprime))\n",
        "    for i in range(D ** k):\n",
        "        for j in range(D ** kprime):\n",
        "            # BUG: THIS NEXT LINE MUST BE WRONG!!\n",
        "            outimage[:, :, i * D ** kprime + j] = sig.correlate2d(bigimage[:, :, i], ff[:, :, j], mode=\"valid\")\n",
        "    return outimage.reshape(outshape)"
      ],
      "metadata": {
        "id": "qTkOpoAEx--W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now plot convlutions of images with filters\n",
        "# - for example: \"(scalar image) \\star (pseudovector 0)\"\n",
        "sstarv = convolve_2d_torus(scalar_image, vfilters[1])\n",
        "sstars = convolve_2d_torus(scalar_image, filters[0])\n",
        "vstars = convolve_2d_torus(vector_image, filters[0])\n",
        "vstarv = convolve_2d_torus(vector_image, vfilters[1])\n",
        "vstarpv = convolve_2d_torus(vector_image, pvfilters[1])"
      ],
      "metadata": {
        "id": "T-FKunLZx2M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
        "plt.imshow(scalar_image, origin=\"lower\")\n",
        "plt.quiver(pxs.flatten(), pys.flatten(),\n",
        "           sstarv[:, :, 0].flatten(), sstarv[:, :, 1].flatten(),\n",
        "           color=\"r\")\n",
        "plt.xlim(-0.5, N-0.5)\n",
        "plt.ylim(-0.5, N-0.5)\n",
        "plt.title(\"scalar image STAR vector filter\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KD1X3NWY0j8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now show a nonlinear, local, scalar function of the scalar image\n",
        "plt.imshow(np.sum(sstarv * sstarv, axis=-1), origin=\"lower\")\n",
        "plt.title(\"squared norm of the above vectors\")"
      ],
      "metadata": {
        "id": "VKnKaltAyzDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
        "plt.imshow(vstarv[:, :, 0, 0] + vstarv[:, :, 1, 1], origin=\"lower\")\n",
        "plt.quiver(pxs.flatten(), pys.flatten(),\n",
        "           vector_image[:, :, 0].flatten(), vector_image[:, :, 1].flatten(),\n",
        "           color=\"r\")\n",
        "plt.xlim(-0.5, N-0.5)\n",
        "plt.ylim(-0.5, N-0.5)\n",
        "plt.title(\"vec image STAR vec filter, contracted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1fuByo5S8xSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
        "plt.imshow(vstarpv[:, :, 0, 0] + vstarpv[:, :, 1, 1], origin=\"lower\")\n",
        "plt.quiver(pxs.flatten(), pys.flatten(),\n",
        "           vector_image[:, :, 0].flatten(), vector_image[:, :, 1].flatten(),\n",
        "           color=\"r\")\n",
        "plt.xlim(-0.5, N-0.5)\n",
        "plt.ylim(-0.5, N-0.5)\n",
        "plt.title(\"vec image STAR pvec filter, contracted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ANMdmGVnB_h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EC9b9xxh2aXI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "group_averaging.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}