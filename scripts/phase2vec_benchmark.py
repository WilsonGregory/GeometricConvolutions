#generate gravitational field
import os
import numpy as np
import sys
from functools import partial
import argparse
import time
from scipy.special import binom

import jax.numpy as jnp
import jax.random as random
import optax

import geometricconvolutions.geometric as geom
import geometricconvolutions.ml as ml

# Copied from phase2vec

def load_dataset(data_path):
    # Load data
    X_train = np.load(os.path.join(data_path, 'X_train.npy'))
    X_test = np.load(os.path.join(data_path, 'X_test.npy'))

    # Load labels
    y_train = np.load(os.path.join(data_path, 'y_train.npy'))
    y_test = np.load(os.path.join(data_path, 'y_test.npy'))

    # Load pars
    p_train = np.load(os.path.join(data_path, 'p_train.npy'))
    p_test = np.load(os.path.join(data_path, 'p_test.npy'))
    return X_train, X_test, y_train, y_test, p_train, p_test

def library_size(dim, poly_order, include_sine=False, include_exp=False, include_constant=True):
    """
    Calculate library size for a given polynomial order. Taken from `https://github.com/kpchamp/SindyAutoencoders`

    """
    l = 0
    for k in range(poly_order+1):
        l += int(binom(dim+k-1,k))
    if include_sine:
        l += dim
    if include_exp:
        l+= dim
    if not include_constant:
        l -= 1
    return l

def sindy_library(X, poly_order, include_sine=False, include_exp=False):
    """
    Generate a library of polynomials of order poly_order. Taken from `https://github.com/kpchamp/SindyAutoencoders`
    """
    m,n = X.shape # samples x dim
    l = library_size(n, poly_order, include_sine=include_sine, include_exp=include_exp, include_constant=True)
    library = np.ones((m,l), dtype=X.dtype)
    index = 1
    
    library_terms = []

    for i in range(n):
        library[:,index] = X[:,i]
        index += 1
        library_terms.append(r'$x_{}$'.format(i))

    if poly_order > 1:
        for i in range(n):
            for j in range(i,n):
                library[:,index] = X[:,i]*X[:,j]
                index += 1
                library_terms.append(r'$x_{}x_{}$'.format(i,j))


    if poly_order > 2:
        for i in range(n):
            for j in range(i,n):
                for k in range(j,n):
                    library[:,index] = X[:,i]*X[:,j]*X[:,k]
                    index += 1
                    library_terms.append(r'$x_{}x_{}x_{}$'.format(i,j,k))

    if poly_order > 3:
        for i in range(n):
            for j in range(i,n):
                for k in range(j,n):
                    for q in range(k,n):
                        library[:,index] = X[:,i]*X[:,j]*X[:,k]*X[:,q]
                        index += 1
                        library_terms.append(r'$x_{}x_{}x_{}x_{}$'.format(i,j,k,q))

                    
    if poly_order > 4:
        for i in range(n):
            for j in range(i,n):
                for k in range(j,n):
                    for q in range(k,n):
                        for r in range(q,n):
                            library[:,index] = X[:,i]*X[:,j]*X[:,k]*X[:,q]*X[:,r]
                            index += 1
                            library_terms.append(r'$x_{}x_{}x_{}x_{}x_{}$'.format(i,j,k,q,r))

    # Consolidate exponents
    for t, term in enumerate(library_terms):
        if 'sin' in term or 'e' in term: continue
        all_exps = []
        for i in range(n):
            all_exps.append(term.count(str(i)))
        new_term = ''
        for e, exp in enumerate(all_exps):
            if exp == 0: continue
            if exp == 1:
                new_term += 'x_{}'.format(e)
            else:
                new_term += 'x_{}^{}'.format(e,exp)
        new_term = r'${}$'.format(new_term)
        library_terms[t] = new_term
    # Add constant term
    library_terms.insert(0,'1')
    return library, library_terms

def fully_connected_layer(params, param_idx, x, width):
    weights_shape = (width, len(x))
    weights_size = width * len(x)
    W = params[param_idx:(param_idx + weights_size)].reshape(weights_shape)
    param_idx += weights_size
    return W @ x, param_idx

def net(params, x, D, is_torus, conv_filters, return_params=False):
    embedding_d = 100
    num_coeffs = library_size(D,3)
    img_N, img_k = geom.parse_shape(x.shape, D)
    layer = { img_k: jnp.expand_dims(x, axis=0) }
    conv_filters = ml.make_layer(conv_filters)

    # Convolution on the vector field generated by the ODE
    layer, param_idx = ml.conv_layer_fixed_filters(
        params,
        0,
        conv_filters, 
        layer, 
        D, 
        is_torus, 
        depth=1,
        stride=(2,)*D, 
        padding='VALID',
    )
    layer = ml.relu_layer(layer, D)
    #batch norm needed

    layer, param_idx = ml.conv_layer_fixed_filters(
        params,
        int(param_idx),
        conv_filters, 
        layer, 
        D, 
        is_torus, 
        depth=1,
        stride=(2,)*D, 
        padding='VALID',
    )
    layer = ml.relu_layer(layer, D)
    # batch norm needed

    layer, param_idx = ml.conv_layer_fixed_filters(
        params,
        int(param_idx),
        conv_filters, 
        layer, 
        D, 
        is_torus, 
        depth=1,
        stride=(2,)*D, 
        padding='VALID',
    )
    layer = ml.relu_layer(layer, D)
    # batch norm?

    # Embed the ODE in a d=100 vector
    embedded_ode = jnp.zeros(embedding_d)
    for image in layer.values():
        vectorized_image = image.reshape(-1)
        layer_out, param_idx = fully_connected_layer(params, int(param_idx), vectorized_image, embedding_d)
        embedded_ode += layer_out

    # Pass the embedded ode through a 2 layer MLP to get the coefficients of poly ode
    layer_vec, param_idx = fully_connected_layer(params, int(param_idx), embedded_ode, 128)
    # batch norm, dropout needed
    layer_vec, param_idx = fully_connected_layer(params, int(param_idx), layer_vec, 128)
    # batch norm, dropout needed
    coeffs, param_idx = fully_connected_layer(params, int(param_idx), layer_vec, num_coeffs * D)
    coeffs = coeffs.reshape((num_coeffs,D))

    # generate function library. Don't need to do this every time ofc
    spatial_coords = [jnp.linspace(mn, mx, img_N) for (mn, mx) in zip([-1.,-1.], [1.,1.])]
    mesh = jnp.meshgrid(*spatial_coords)
    L = jnp.concatenate([ms[..., None] for ms in mesh], axis=-1)
    library, _ = sindy_library(L.reshape(img_N**D,D), 3)

    # multiply the functions by the coefficients
    recon_x = (library @ coeffs).reshape(img_N, img_N, D)
    return (recon_x, coeffs, param_idx) if return_params else (recon_x, coeffs)

def map_and_loss(params, x, y, conv_filters, D, is_torus, eps=1e-5, beta=1e-3):
    '''Euclidean distance between two arrays with spatial dimensions.
      Normalizes pointwise across the spatial dimension by the norm of the second argument'''
    # Normalized pointwise loss from the paper
    recon, coeffs = net(params, x, D, is_torus, conv_filters)

    m_gt = jnp.linalg.norm(y, axis=D) #this maybe only works when k=1, its a vector field
    den =jnp.expand_dims(m_gt + eps, axis=D) #ensure division is broadcast correctly
    # den shape will be (N**D, 1)
    # recon shape will be (N**D, D), since k=1

    #should be sum rather than mean?
    normalized_loss = jnp.sqrt(jnp.mean(((recon - y)**2) / den)) #normalize pointwise by gt norm

    sparsity_loss = jnp.mean(jnp.abs(coeffs))
    return normalized_loss + beta * sparsity_loss

def baseline_net(params, x, D, is_torus, return_params=False):
    embedding_d = 100
    num_coeffs = library_size(D,3)
    img_N, _ = geom.parse_shape(x.shape, D)
    layer = { 0: jnp.moveaxis(x, -1, 0) } #for the baseline model, the vector dimensions become channels
    assert layer[0].shape == (2, img_N, img_N)

    # Convolution on the vector field generated by the ODE
    layer, param_idx = ml.conv_layer_free_filters(
        params,
        0,
        layer, 
        D, 
        is_torus, 
        M=3,
        depth=128,
        stride=(2,)*D, 
        padding='VALID',
    )
    layer = ml.relu_layer(layer, D)
    #batch norm needed

    layer, param_idx = ml.conv_layer_free_filters(
        params,
        int(param_idx),
        layer, 
        D, 
        is_torus, 
        M=3,
        depth=128,
        stride=(2,)*D, 
        padding='VALID',
    )
    layer = ml.relu_layer(layer, D)
    # batch norm needed

    layer, param_idx = ml.conv_layer_free_filters(
        params,
        int(param_idx),
        layer, 
        D, 
        is_torus, 
        M=3,
        depth=128,
        stride=(2,)*D, 
        padding='VALID',
    )
    layer = ml.relu_layer(layer, D)
    # batch norm?

    # Embed the ODE in a d=100 vector
    embedded_ode = jnp.zeros(embedding_d)
    for image in layer.values():
        vectorized_image = image.reshape(-1)
        layer_out, param_idx = fully_connected_layer(params, int(param_idx), vectorized_image, embedding_d)
        embedded_ode += layer_out

    # Pass the embedded ode through a 2 layer MLP to get the coefficients of poly ode
    layer_vec, param_idx = fully_connected_layer(params, int(param_idx), embedded_ode, 128)
    # batch norm, dropout needed
    layer_vec, param_idx = fully_connected_layer(params, int(param_idx), layer_vec, 128)
    # batch norm, dropout needed
    coeffs, param_idx = fully_connected_layer(params, int(param_idx), layer_vec, num_coeffs * D)
    coeffs = coeffs.reshape((num_coeffs,D))

    # generate function library. Don't need to do this every time ofc
    spatial_coords = [jnp.linspace(mn, mx, img_N) for (mn, mx) in zip([-1.,-1.], [1.,1.])]
    mesh = jnp.meshgrid(*spatial_coords)
    L = jnp.concatenate([ms[..., None] for ms in mesh], axis=-1)
    library, _ = sindy_library(L.reshape(img_N**D,D), 3)

    # multiply the functions by the coefficients
    recon_x = (library @ coeffs).reshape(img_N, img_N, D)
    return (recon_x, coeffs, param_idx) if return_params else (recon_x, coeffs)

def baseline_map_and_loss(params, x, y, D, is_torus, eps=1e-5, beta=1e-3):
    '''Euclidean distance between two arrays with spatial dimensions.
      Normalizes pointwise across the spatial dimension by the norm of the second argument'''
    # Normalized pointwise loss from the paper
    recon, coeffs = baseline_net(params, x, D, is_torus)

    m_gt = jnp.linalg.norm(y, axis=D) #this maybe only works when k=1, its a vector field
    den =jnp.expand_dims(m_gt + eps, axis=D) #ensure division is broadcast correctly
    # den shape will be (N**D, 1)
    # recon shape will be (N**D, D), since k=1

    #should be sum rather than mean?
    normalized_loss = jnp.sqrt(jnp.mean(((recon - y)**2) / den)) #normalize pointwise by gt norm

    sparsity_loss = jnp.mean(jnp.abs(coeffs))
    return normalized_loss + beta * sparsity_loss

def handleArgs(argv):
    parser = argparse.ArgumentParser()
    parser.add_argument('-e', '--epochs', help='number of epochs', type=float, default=200)
    parser.add_argument('-lr', help='learning rate', type=float, default=0.1)
    parser.add_argument('-batch', help='batch size', type=int, default=1)
    parser.add_argument('-seed', help='the random number seed', type=int, default=None)
    parser.add_argument('-s', '--save', help='file name to save the params', type=str, default=None)
    parser.add_argument('-l', '--load', help='file name to load params from', type=str, default=None)
    parser.add_argument('-v', '--verbose', help='levels of print statements during training', type=int, default=1)

    args = parser.parse_args()

    return (
        args.epochs,
        args.lr,
        args.batch,
        args.seed,
        args.save,
        args.load,
        args.verbose,
    )

# Main
epochs, lr, batch_size, seed, save_file, load_file, verbose = handleArgs(sys.argv)

D = 2

key = random.PRNGKey(seed if seed else time.time_ns())

# start with basic 3x3 scalar, vector, and 2nd order tensor images
conv_filters = geom.get_invariant_filters(
    Ms=[3],
    ks=[0,1],
    parities=[0],
    D=D,
    operators=geom.make_all_operators(D),
    return_list=True,
)

train_data_path = '../phase2vec/output/data/polynomial'
X_train_data, X_val_data, y_train, y_val, p_train, p_val = load_dataset(train_data_path)
# print(X_train.shape) # (samples, d,n,n)
X_train = [geom.GeometricImage(data,0,D,False) for data in X_train_data.transpose(0,2,3,1)]
X_val = [geom.GeometricImage(data,0,D,False) for data in X_val_data.transpose(0,2,3,1)]

one_point = X_train[0]

huge_params = jnp.ones(100000000)
# _, _, num_params = net(
#     huge_params,
#     one_point.data,
#     D,
#     False, #is_torus
#     conv_filters,
#     return_params=True,
# )

_, _, num_params = baseline_net(
    huge_params,
    one_point.data,
    D,
    False, #is_torus
    return_params=True,
)

print('Num params:', num_params)

key, subkey = random.split(key)
params = 0.1*random.normal(subkey, shape=(num_params,))

params, _, _ = ml.train(
    X_train,
    X_train, #reconstruction, so we want to get back to the input
    # partial(map_and_loss, D=D, is_torus=False, conv_filters=conv_filters),
    partial(baseline_map_and_loss, D=D, is_torus=False),
    params,
    key,
    ml.EpochStop(epochs, verbose=verbose),
    batch_size=batch_size,
    optimizer=optax.adam(optax.exponential_decay(lr, transition_steps=int(len(X_train) / batch_size), decay_rate=0.995)),
    # validation_X=validation_X,
    # validation_Y=validation_Y,
    save_params=save_file,
)

if (save_file):
    jnp.save(save_file, params)

# plt.rcParams['font.family'] = 'serif'
# plt.rcParams['font.serif'] = 'STIXGeneral'
# plt.tight_layout()
